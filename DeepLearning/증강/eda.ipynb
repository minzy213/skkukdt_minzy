{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "wordnet = {}\n",
    "with open(\"wordnet.pickle\", \"rb\") as f:\n",
    "\twordnet = pickle.load(f)\n",
    "\n",
    "\n",
    "# 한글만 남기고 나머지는 삭제\n",
    "def get_only_hangul(line):\n",
    "\tparseText= re.compile('/ ^[ㄱ-ㅎㅏ-ㅣ가-힣]*$/').sub('',line)\n",
    "\n",
    "\treturn parseText\n",
    "\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "def synonym_replacement(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\trandom_word_list = list(set([word for word in words]))\n",
    "\trandom.shuffle(random_word_list)\n",
    "\tnum_replaced = 0\n",
    "\tfor random_word in random_word_list:\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tif len(synonyms) >= 1:\n",
    "\t\t\tsynonym = random.choice(list(synonyms))\n",
    "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
    "\t\t\tnum_replaced += 1\n",
    "\t\tif num_replaced >= n:\n",
    "\t\t\tbreak\n",
    "\n",
    "\tif len(new_words) != 0:\n",
    "\t\tsentence = ' '.join(new_words)\n",
    "\t\tnew_words = sentence.split(\" \")\n",
    "\n",
    "\telse:\n",
    "\t\tnew_words = \"\"\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "\n",
    "def get_synonyms(word):\n",
    "\tsynomyms = []\n",
    "\n",
    "\ttry:\n",
    "\t\tfor syn in wordnet[word]:\n",
    "\t\t\tfor s in syn:\n",
    "\t\t\t\tsynomyms.append(s)\n",
    "\texcept:\n",
    "\t\tpass\n",
    "\n",
    "\treturn synomyms\n",
    "\n",
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "def random_deletion(words, p):\n",
    "\tif len(words) == 1:\n",
    "\t\treturn words\n",
    "\n",
    "\tnew_words = []\n",
    "\tfor word in words:\n",
    "\t\tr = random.uniform(0, 1)\n",
    "\t\tif r > p:\n",
    "\t\t\tnew_words.append(word)\n",
    "\n",
    "\tif len(new_words) == 0:\n",
    "\t\trand_int = random.randint(0, len(words)-1)\n",
    "\t\treturn [words[rand_int]]\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "def random_swap(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tnew_words = swap_word(new_words)\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
    "\trandom_idx_2 = random_idx_1\n",
    "\tcounter = 0\n",
    "\n",
    "\twhile random_idx_2 == random_idx_1:\n",
    "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter > 3:\n",
    "\t\t\treturn new_words\n",
    "\n",
    "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "def random_insertion(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tadd_word(new_words)\n",
    "\t\n",
    "\treturn new_words\n",
    "\n",
    "\n",
    "def add_word(new_words):\n",
    "\tsynonyms = []\n",
    "\tcounter = 0\n",
    "\twhile len(synonyms) < 1:\n",
    "\t\tif len(new_words) >= 1:\n",
    "\t\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "\t\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\t\tcounter += 1\n",
    "\t\telse:\n",
    "\t\t\trandom_word = \"\"\n",
    "\n",
    "\t\tif counter >= 10:\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\trandom_synonym = synonyms[0]\n",
    "\trandom_idx = random.randint(0, len(new_words)-1)\n",
    "\tnew_words.insert(random_idx, random_synonym)\n",
    "\n",
    "\n",
    "\n",
    "def EDA(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=9):\n",
    "\t# sentence = get_only_hangul(sentence)\n",
    "\twords = sentence.split(' ')\n",
    "\twords = [word for word in words if word != \"\"]\n",
    "\tnum_words = len(words)\n",
    "\n",
    "\taugmented_sentences = []\n",
    "\tnum_new_per_technique = int(num_aug/4) + 1\n",
    "\n",
    "\tn_sr = max(1, int(alpha_sr*num_words))\n",
    "\tn_ri = max(1, int(alpha_ri*num_words))\n",
    "\tn_rs = max(1, int(alpha_rs*num_words))\n",
    "\n",
    "\t# sr\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = synonym_replacement(words, n_sr)\n",
    "\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t# ri\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = random_insertion(words, n_ri)\n",
    "\t\taugmented_sentences.append(' '.join(a_words))\n",
    "\n",
    "\t# rs\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = random_swap(words, n_rs)\n",
    "\t\taugmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "\t# rd\n",
    "\tfor _ in range(num_new_per_technique):\n",
    "\t\ta_words = random_deletion(words, p_rd)\n",
    "\t\taugmented_sentences.append(\" \".join(a_words))\n",
    "\n",
    "\t# augmented_sentences = [sentence for sentence in augmented_sentences]\n",
    "\trandom.shuffle(augmented_sentences)\n",
    "\n",
    "\tif num_aug >= 1:\n",
    "\t\taugmented_sentences = augmented_sentences[:num_aug]\n",
    "\telse:\n",
    "\t\tkeep_prob = num_aug / len(augmented_sentences)\n",
    "\t\taugmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
    "\n",
    "\taugmented_sentences.append(sentence)\n",
    "\n",
    "\treturn augmented_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'../data/train_final.csv')\n",
    "df = df[df['immoral'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sent in df['text'].values:\n",
    "    li.extend(EDA(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = pd.DataFrame(li, columns = ['text'])\n",
    "li['immoral'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445318"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = li.drop_duplicates('text')\n",
    "len(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369609"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org = pd.read_csv(r'../data/train_final.csv')\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778841"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "org = org[org['immoral'] == 0]\n",
    "cn = pd.concat([org, li])\n",
    "len(cn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cn.to_csv(r'../data/train_aug2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mzp",
   "language": "python",
   "name": "mzpark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
