{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt # komoran, han, kkma\n",
    "from jamo import h2j, j2hcj\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 가져오기, 학습 데이터셋으로 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인벤에서 수집한 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23136\\2151298477.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  immoral = pd.read_csv(r'data\\immoral.txt', sep = 'asssssssss', header = None)\n"
     ]
    }
   ],
   "source": [
    "immoral = pd.read_csv(r'data\\immoral.txt', sep = 'asssssssss', header = None)\n",
    "immoral.columns = ['text']\n",
    "immoral['immoral'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_23136\\2827705178.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  clean = pd.read_csv(r'data\\clean.txt', sep = 'asssssssss', header = None)\n"
     ]
    }
   ],
   "source": [
    "clean = pd.read_csv(r'data\\clean.txt', sep = 'asssssssss', header = None)\n",
    "clean.columns = ['text']\n",
    "clean['immoral'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## op.gg 데이터 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lii = []\n",
    "headers = {\n",
    "    'Referer':'https://www.op.gg/',\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36'\n",
    "}\n",
    "for chm in champ:\n",
    "    n = 1\n",
    "    while 1:\n",
    "        url = f'https://op.gg/api/v1.0/internal/bypass/champions/{chm}/comments?&sort=popular&page={n}&limit=100&hl=ko_KR&is_latest_version=false'\n",
    "        n += 1\n",
    "        resp = requests.get(url, headers = headers)\n",
    "        dict_ch = json.loads(resp.text)\n",
    "        if len(dict_ch['data']) == 0:\n",
    "            break\n",
    "        \n",
    "        for dat in dict_ch['data']:\n",
    "            lii.append(dat['content'].replace('\\n', ''))\n",
    "        time.sleep(5)\n",
    "    \n",
    "    print(chm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>immoral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>얘 와맆에 곰돌이가 에어본 시키는 거 생겼던데 여기에도 생기나</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>자기고향 찾아오네</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>몇달만의 고향이냐</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>점멸 있을 때 한정 1티어</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스킬 사거리 표시 없이 하면 암걸리는 챔</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7968</th>\n",
       "      <td>의외로 꼴짤이 별로 없음</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7969</th>\n",
       "      <td>나피리 근데 초반 라인전도 약하고 카운터도 많음.그리고 돌진기가 다른 암살자와 다르...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7970</th>\n",
       "      <td>0/6/0 야스오:야이 개쌔꺄 이게 챔이냐 야발4/0/2 나피리:개 맞는데0/8/0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7971</th>\n",
       "      <td>얘 한테 지면 사람아닌래끼다버프좀 하고 성능좀 버프히라못 쓸 정도다</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7972</th>\n",
       "      <td>버프좀 해줘</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7973 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text immoral\n",
       "0                    얘 와맆에 곰돌이가 에어본 시키는 거 생겼던데 여기에도 생기나        \n",
       "1                                             자기고향 찾아오네        \n",
       "2                                             몇달만의 고향이냐        \n",
       "3                                        점멸 있을 때 한정 1티어        \n",
       "4                                스킬 사거리 표시 없이 하면 암걸리는 챔        \n",
       "...                                                 ...     ...\n",
       "7968                                      의외로 꼴짤이 별로 없음        \n",
       "7969  나피리 근데 초반 라인전도 약하고 카운터도 많음.그리고 돌진기가 다른 암살자와 다르...        \n",
       "7970  0/6/0 야스오:야이 개쌔꺄 이게 챔이냐 야발4/0/2 나피리:개 맞는데0/8/0...        \n",
       "7971              얘 한테 지면 사람아닌래끼다버프좀 하고 성능좀 버프히라못 쓸 정도다        \n",
       "7972                                             버프좀 해줘        \n",
       "\n",
       "[7973 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lii = pd.DataFrame(lii, columns = ['text'])\n",
    "df_lii['immoral'] = ''\n",
    "df_lii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### op.gg 데이터 직접 라벨링, 라벨링 된 csv 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lii.to_csv(r'data/champions.csv', index = False)\n",
    "df_lii = pd.read_csv(r'data/champions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10380\\2204739627.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'False' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  champions.loc[champions['immoral'] == 0, 'immoral'] = False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>immoral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>얘 와맆에 곰돌이가 에어본 시키는 거 생겼던데 여기에도 생기나</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>자기고향 찾아오네</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>몇달만의 고향이냐</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>점멸 있을 때 한정 1티어</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>스킬 사거리 표시 없이 하면 암걸리는 챔</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>클레드로 굶드라랑 월식 못 가게 너프먹는다니까 진짜 ㅈ같아서 겜 못해먹겠네 월식은 ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>진짜 개사기임아니 협곡말고 롤체 학살자 클레드요</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>진짜 태불방 롤백 시킬거 아니면 클레드는 건들면 안되지 ㅋㅋㅋ 선넘네 진짜</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>\"바텀에서 겨우 더블킬을 했다.\"\"나팔소리가 들렸다.\"\"여름이었다.\"(제압되었습니다!)</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>ㄹㅇ 누군지도 몰랐다가 호되게 당함;;;</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6463 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text immoral\n",
       "0                    얘 와맆에 곰돌이가 에어본 시키는 거 생겼던데 여기에도 생기나   False\n",
       "1                                             자기고향 찾아오네   False\n",
       "2                                             몇달만의 고향이냐   False\n",
       "3                                        점멸 있을 때 한정 1티어   False\n",
       "4                                스킬 사거리 표시 없이 하면 암걸리는 챔   False\n",
       "...                                                 ...     ...\n",
       "6458  클레드로 굶드라랑 월식 못 가게 너프먹는다니까 진짜 ㅈ같아서 겜 못해먹겠네 월식은 ...    True\n",
       "6459                         진짜 개사기임아니 협곡말고 롤체 학살자 클레드요   False\n",
       "6460          진짜 태불방 롤백 시킬거 아니면 클레드는 건들면 안되지 ㅋㅋㅋ 선넘네 진짜   False\n",
       "6461   \"바텀에서 겨우 더블킬을 했다.\"\"나팔소리가 들렸다.\"\"여름이었다.\"(제압되었습니다!)   False\n",
       "6462                             ㄹㅇ 누군지도 몰랐다가 호되게 당함;;;   False\n",
       "\n",
       "[6463 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champions = pd.read_csv(r'data\\champions.csv')\n",
    "champions.columns = ['text','immoral']\n",
    "champions.loc[champions['immoral'] == 0, 'immoral'] = False\n",
    "champions.loc[champions['immoral'] == 1, 'immoral'] = True\n",
    "champions = champions.fillna(False)\n",
    "champions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ai hub 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai hub train set\n",
    "li = []\n",
    "for i in range(1, 6):\n",
    "    with open(r'.\\data\\train\\labled\\talksets-train-' + str(i) + '.json') as f:\n",
    "        data = json.load(f)\n",
    "    for d in data:\n",
    "        for s in d['sentences']:\n",
    "            li.append([s['origin_text'], s['is_immoral'], s['intensity'], \n",
    "                    'CENSURE' in s['types'], 'HATE' in s['types'], 'DISCRIMINATION' in s['types'], \n",
    "                    'SEXUAL' in s['types'], 'ABUSE' in s['types'], 'VIOLENCE' in s['types'], 'CRIME' in s['types']])\n",
    "            \n",
    "train = pd.DataFrame(li, columns=['text', 'immoral', 'intensity', 'CENSURE', 'HATE', 'DISCRIMINATION', 'SEXUAL', 'ABUSE', 'VIOLENCE', 'CRIME'])\n",
    "train['text'] = train['text'].apply(lambda x : re.sub('#@.+?#', '', x.replace('#@#', '')))\n",
    "\n",
    "train['immoral'] = (train['SEXUAL'] == True) | (train['ABUSE'] == True)\n",
    "train_set = train[['text', 'immoral']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai hub test set\n",
    "li = []\n",
    "with open(r'.\\data\\valid\\labled\\talksets-train-6.json') as f:\n",
    "    data = json.load(f)\n",
    "for d in data:\n",
    "    for s in d['sentences']:\n",
    "        li.append([s['origin_text'], s['is_immoral'], s['intensity'], \n",
    "                'CENSURE' in s['types'], 'HATE' in s['types'], 'DISCRIMINATION' in s['types'], \n",
    "                'SEXUAL' in s['types'], 'ABUSE' in s['types'], 'VIOLENCE' in s['types'], 'CRIME' in s['types']])\n",
    "test = pd.DataFrame(li, columns=['text', 'immoral', 'intensity', 'CENSURE', 'HATE', 'DISCRIMINATION', 'SEXUAL', 'ABUSE', 'VIOLENCE', 'CRIME'])\n",
    "\n",
    "test['text'] = test['text'].apply(lambda x : re.sub('#@.+?#', '', x.replace('#@#', '')))\n",
    "\n",
    "test['immoral'] = (test['SEXUAL'] == True) | (test['ABUSE'] == True)\n",
    "test_set = test[['text', 'immoral']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## badwords 가져오기\n",
    "https://github.com/organization/Gentleman/blob/master/resources/badwords.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# badwords, train\n",
    "with open(r\".\\data\\train\\labled\\badwords.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "badwords = pd.DataFrame(data['badwords'], columns= ['text'])\n",
    "badwords['immoral'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 가져온 데이터 train/test 나눠서 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_sl = int(len(immoral) * 0.8)\n",
    "cl_sl = int(len(clean) * 0.8)\n",
    "cp_sl = int(len(champions) * 0.8)\n",
    "bw_sl = int(len(badwords) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((369610, 2), (46830, 2))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train_set, immoral[:im_sl], clean[:cl_sl], badwords[:bw_sl], champions[:cp_sl]])\n",
    "test = pd.concat([test_set, immoral[im_sl:], clean[cl_sl:], badwords[bw_sl:], champions[cp_sl:]])\n",
    "train['immoral'] = train['immoral'].apply(lambda x : 1 if x == True else 0)\n",
    "test['immoral'] = test['immoral'].apply(lambda x : 1 if x == True else 0)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((369609, 2), (46830, 2))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train.to_csv(r'data/train_final.csv', index = False)\n",
    "# test.to_csv(r'data/test_final.csv', index = False)\n",
    "train = pd.read_csv(r'data/train_final.csv')\n",
    "test = pd.read_csv(r'data/test_final.csv')\n",
    "# train = pd.read_csv(r'data/train_aug.csv')\n",
    "# test = pd.read_csv(r'data/test_aug.csv')\n",
    "\n",
    "# test = pd.read_csv(r'data/champions_t.csv')\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>immoral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ㅇㅒ ㅇㅘㄹㅣㅍㅇㅔ ㄱㅗㅁㄷㅗㄹㅇㅣㄱㅏ ㅇㅔㅇㅓㅂㅗㄴ ㅅㅣㅋㅣㄴㅡㄴ ㄱㅓ ㅅㅐㅇㄱㅕ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ㅈㅏㄱㅣㄱㅗㅎㅑㅇ ㅊㅏㅈㅇㅏㅇㅗㄴㅔ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ㅁㅕㅊㄷㅏㄹㅁㅏㄴㅇㅢ ㄱㅗㅎㅑㅇㅇㅣㄴㅑ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ㅈㅓㅁㅁㅕㄹ ㅇㅣㅆㅇㅡㄹ ㄸㅐ ㅎㅏㄴㅈㅓㅇ 1ㅌㅣㅇㅓ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ㅅㅡㅋㅣㄹ ㅅㅏㄱㅓㄹㅣ ㅍㅛㅅㅣ ㅇㅓㅄㅇㅣ ㅎㅏㅁㅕㄴ ㅇㅏㅁㄱㅓㄹㄹㅣㄴㅡㄴ ㅊㅐㅁ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6457</th>\n",
       "      <td>ㄹㅏㅇㅣㄴㅈㅓㄴㅇㅔ ㄴㅏㄹㅁㅓㄱㅎㅐㅅㅓ ㅎㅏㄴ 6ㅋㅣㄹ ㄷㅙㄷㅗ ㅃㅏㄹㄹㅣ ㅁㅗㅅㄲ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>ㅈㅣㄴㅉㅏ ㄱㅐㅅㅏㄱㅣㅇㅣㅁㅇㅏㄴㅣ ㅎㅕㅂㄱㅗㄱㅁㅏㄹㄱㅗ ㄹㅗㄹㅊㅔ ㅎㅏㄱㅅㅏㄹㅈㅏ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>ㅈㅣㄴㅉㅏ ㅌㅐㅂㅜㄹㅂㅏㅇ ㄹㅗㄹㅂㅐㄱ ㅅㅣㅋㅣㄹㄱㅓ ㅇㅏㄴㅣㅁㅕㄴ ㅋㅡㄹㄹㅔㄷㅡㄴ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6461</th>\n",
       "      <td>\"ㅂㅏㅌㅓㅁㅇㅔㅅㅓ ㄱㅕㅇㅜ ㄷㅓㅂㅡㄹㅋㅣㄹㅇㅡㄹ ㅎㅐㅆㄷㅏ.\"\"ㄴㅏㅍㅏㄹㅅㅗㄹㅣㄱ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6462</th>\n",
       "      <td>ㄹㅇ ㄴㅜㄱㅜㄴㅈㅣㄷㅗ ㅁㅗㄹㄹㅏㅆㄷㅏㄱㅏ ㅎㅗㄷㅚㄱㅔ ㄷㅏㅇㅎㅏㅁ;;;</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4859 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  immoral\n",
       "0     ㅇㅒ ㅇㅘㄹㅣㅍㅇㅔ ㄱㅗㅁㄷㅗㄹㅇㅣㄱㅏ ㅇㅔㅇㅓㅂㅗㄴ ㅅㅣㅋㅣㄴㅡㄴ ㄱㅓ ㅅㅐㅇㄱㅕ...      0.0\n",
       "1                                   ㅈㅏㄱㅣㄱㅗㅎㅑㅇ ㅊㅏㅈㅇㅏㅇㅗㄴㅔ      0.0\n",
       "2                                 ㅁㅕㅊㄷㅏㄹㅁㅏㄴㅇㅢ ㄱㅗㅎㅑㅇㅇㅣㄴㅑ      0.0\n",
       "3                         ㅈㅓㅁㅁㅕㄹ ㅇㅣㅆㅇㅡㄹ ㄸㅐ ㅎㅏㄴㅈㅓㅇ 1ㅌㅣㅇㅓ      0.0\n",
       "4         ㅅㅡㅋㅣㄹ ㅅㅏㄱㅓㄹㅣ ㅍㅛㅅㅣ ㅇㅓㅄㅇㅣ ㅎㅏㅁㅕㄴ ㅇㅏㅁㄱㅓㄹㄹㅣㄴㅡㄴ ㅊㅐㅁ      0.0\n",
       "...                                                 ...      ...\n",
       "6457  ㄹㅏㅇㅣㄴㅈㅓㄴㅇㅔ ㄴㅏㄹㅁㅓㄱㅎㅐㅅㅓ ㅎㅏㄴ 6ㅋㅣㄹ ㄷㅙㄷㅗ ㅃㅏㄹㄹㅣ ㅁㅗㅅㄲ...      0.0\n",
       "6459  ㅈㅣㄴㅉㅏ ㄱㅐㅅㅏㄱㅣㅇㅣㅁㅇㅏㄴㅣ ㅎㅕㅂㄱㅗㄱㅁㅏㄹㄱㅗ ㄹㅗㄹㅊㅔ ㅎㅏㄱㅅㅏㄹㅈㅏ...      0.0\n",
       "6460  ㅈㅣㄴㅉㅏ ㅌㅐㅂㅜㄹㅂㅏㅇ ㄹㅗㄹㅂㅐㄱ ㅅㅣㅋㅣㄹㄱㅓ ㅇㅏㄴㅣㅁㅕㄴ ㅋㅡㄹㄹㅔㄷㅡㄴ...      0.0\n",
       "6461  \"ㅂㅏㅌㅓㅁㅇㅔㅅㅓ ㄱㅕㅇㅜ ㄷㅓㅂㅡㄹㅋㅣㄹㅇㅡㄹ ㅎㅐㅆㄷㅏ.\"\"ㄴㅏㅍㅏㄹㅅㅗㄹㅣㄱ...      0.0\n",
       "6462           ㄹㅇ ㄴㅜㄱㅜㄴㅈㅣㄷㅗ ㅁㅗㄹㄹㅏㅆㄷㅏㄱㅏ ㅎㅗㄷㅚㄱㅔ ㄷㅏㅇㅎㅏㅁ;;;      0.0\n",
       "\n",
       "[4859 rows x 2 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['immoral'] != 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 자모음으로 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].apply(lambda x : j2hcj(h2j(x)))\n",
    "test['text'] = test['text'].apply(lambda x : j2hcj(h2j(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap rows\n",
    "train = train.sample(frac = 1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToList(text):\n",
    "    li = []\n",
    "    for t in text:\n",
    "        li.append(list(t.strip()))\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자모음 쪼갠 텍스트를 한글자씩 리스트로 만들어서 데이터셋 만든다\n",
    "def textToList(text):\n",
    "    li = []\n",
    "    for t in text:\n",
    "        li.append(list(t))\n",
    "    return li\n",
    "\n",
    "train_list = textToList(train['text'])\n",
    "train_label = train['immoral']\n",
    "\n",
    "test_list = textToList(test['text'])\n",
    "test_label = test['immoral']\n",
    "\n",
    "# X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 최대 길이 정해야되니까 문장 길이 분포가 얼마나 되어있는지 확인한다\n",
    "# li_len = []\n",
    "# for t in train_list:\n",
    "#     li_len.append(len(t))\n",
    "# import seaborn as sns\n",
    "# sns.set_theme(style=\"darkgrid\")\n",
    "# sns.histplot(li_len)\n",
    "## 100으로 자르면 문장 잘리는 아이들 비율이 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 단어 개수:  166\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=110)\n",
    "tokenizer.fit_on_texts(train_list) # 단어 인덱스 구축\n",
    "text_sequences = tokenizer.texts_to_sequences(train_list) # 문자열 -> 인덱스 리스트\n",
    "                                                            # '나는 천재다 나는 멋있다' -> [1, 2, 1, 3]\n",
    "# train data로 fit 시켜준 tokenizer로 test data도 인덱스로 변경\n",
    "text_sequences_test = tokenizer.texts_to_sequences(test_list)\n",
    "\n",
    "word_vocab = tokenizer.word_index # 딕셔너리 형태\n",
    "print(\"전체 단어 개수: \", len(word_vocab)) # 전체 단어 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train input data tensor: (369609, 100)\n",
      "Shape of train label tensor: (369609,)\n",
      "Shape of test input data tensor: (46830, 100)\n",
      "Shape of test label tensor: (46830,)\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100 # 문장 최대 길이\n",
    "\n",
    "X_train = pad_sequences(text_sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='pre') # 문장의 길이가 100 글자가 넘어가면 자르고, 모자르면 0으로 채워 넣는다.\n",
    "y_train = np.array(train_label) # 각 리뷰의 감정을 넘파이 배열로 만든다.\n",
    "\n",
    "X_test = pad_sequences(text_sequences_test, maxlen=MAX_SEQUENCE_LENGTH, padding='pre') # 문장의 길이가 100 글자가 넘어가면 자르고, 모자르면 0으로 채워 넣는다.\n",
    "y_test = np.array(test_label) # 각 리뷰의 감정을 넘파이 배열로 만든다.\n",
    "\n",
    "print('Shape of train input data tensor:', X_train.shape) # 리뷰 데이터의 형태 확인\n",
    "print('Shape of train label tensor:', y_train.shape) # 감정 데이터 형태 확인\n",
    "print('Shape of test input data tensor:', X_test.shape) # 리뷰 데이터의 형태 확인\n",
    "print('Shape of test label tensor:', y_test.shape) # 감정 데이터 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, None, 64)          10688     \n",
      "                                                                 \n",
      " conv1d_48 (Conv1D)          (None, None, 512)         98816     \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, None, 512)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_49 (Conv1D)          (None, None, 512)         1311232   \n",
      "                                                                 \n",
      " max_pooling1d_37 (MaxPoolin  (None, None, 512)        0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_50 (Conv1D)          (None, None, 512)         1835520   \n",
      "                                                                 \n",
      " global_max_pooling1d_5 (Glo  (None, 512)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 8)                 4104      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,260,369\n",
      "Trainable params: 3,260,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Conv1D, GlobalMaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "embedding_dim = 50 # 임베딩 벡터의 차원\n",
    "dropout_ratio = 0.3 # 드롭아웃 비율\n",
    "num_filters = 256 # 커널의 수\n",
    "kernel_size = 3 # 커널의 크기\n",
    "hidden_units = 128 # 뉴런의 수\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(len(word_vocab)+1, embedding_dim))\n",
    "# model.add(Conv1D(256, kernel_size, padding='valid', activation='relu'))\n",
    "# model.add(Conv1D(256, kernel_size, padding='valid', activation='relu'))\n",
    "# model.add(Conv1D(num_filters, kernel_size, padding='valid', activation='relu'))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "# model.add(Dense(hidden_units, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "vocab_size = 30000\n",
    "word_vector_dim = 64\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(len(word_vocab)+1, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(512, 3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(3))\n",
    "model.add(tf.keras.layers.Conv1D(512, 5, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D())\n",
    "model.add(tf.keras.layers.Conv1D(512, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dropout(rate=0.5))\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', loss = 'mean_squared_error', metrics=['accuracy',\n",
    "                                                                            tf.keras.metrics.TrueNegatives(name='true_negatives'),\n",
    "                                                                            tf.keras.metrics.TruePositives(name='true_positives'),\n",
    "                                                                            tf.keras.metrics.FalseNegatives(name='false_negatives'),\n",
    "                                                                            tf.keras.metrics.FalsePositives(name='false_positives')])\n",
    "# 이진 분류이므로 손실함수는 binary_crossentropy 사용, 에폭마다 정확도를 보기 위해 accuracy 적용\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2957/2957 [==============================] - 595s 201ms/step - loss: 0.0843 - accuracy: 0.9018 - true_negatives: 266643.0000 - true_positives: 13.0000 - false_negatives: 28948.0000 - false_positives: 83.0000 - val_loss: 0.0750 - val_accuracy: 0.9036 - val_true_negatives: 66797.0000 - val_true_positives: 0.0000e+00 - val_false_negatives: 7125.0000 - val_false_positives: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "2957/2957 [==============================] - 598s 202ms/step - loss: 0.0739 - accuracy: 0.9107 - true_negatives: 263790.0000 - true_positives: 5499.0000 - false_negatives: 23462.0000 - false_positives: 2936.0000 - val_loss: 0.0692 - val_accuracy: 0.9183 - val_true_negatives: 66164.0000 - val_true_positives: 1722.0000 - val_false_negatives: 5403.0000 - val_false_positives: 633.0000 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "1882/2957 [==================>...........] - ETA: 3:22 - loss: 0.0705 - accuracy: 0.9163 - true_negatives: 167324.0000 - true_positives: 5126.0000 - false_negatives: 13381.0000 - false_positives: 2369.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\code\\skkukdt_minzy\\DeepLearning\\project.ipynb Cell 32\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m early \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m reduce_lr \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     factor\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, \u001b[39m# new_lr = lr * factor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     min_lr\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, batch_size \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early, reduce_lr])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X43sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mconv_red8.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\engine\\training.py:1570\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[0;32m   1569\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[1;32m-> 1570\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1571\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[0;32m   1572\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\callbacks.py:470\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \n\u001b[0;32m    465\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 470\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\callbacks.py:317\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    316\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\callbacks.py:340\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    337\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 340\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    343\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\callbacks.py:388\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m    387\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 388\u001b[0m     hook(batch, logs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[0;32m    391\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\callbacks.py:1081\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1081\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\callbacks.py:1158\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m-> 1158\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprogbar\u001b[39m.\u001b[39;49mupdate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseen, \u001b[39mlist\u001b[39;49m(logs\u001b[39m.\u001b[39;49mitems()), finalize\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\utils\\generic_utils.py:1051\u001b[0m, in \u001b[0;36mProgbar.update\u001b[1;34m(self, current, values, finalize)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         info \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1050\u001b[0m     message \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m info\n\u001b[1;32m-> 1051\u001b[0m     io_utils\u001b[39m.\u001b[39;49mprint_msg(message, line_break\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m   1052\u001b[0m     message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1054\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\utils\\io_utils.py:79\u001b[0m, in \u001b[0;36mprint_msg\u001b[1;34m(message, line_break)\u001b[0m\n\u001b[0;32m     77\u001b[0m         sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(message \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 79\u001b[0m         sys\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mwrite(message)\n\u001b[0;32m     80\u001b[0m     sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[0;32m     81\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\ipykernel\\iostream.py:648\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpub_thread\u001b[39m.\u001b[39mschedule(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[0;32m    647\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 648\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_schedule_flush()\n\u001b[0;32m    650\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(string)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\ipykernel\\iostream.py:545\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    543\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_io_loop\u001b[39m.\u001b[39mcall_later(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflush_interval, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flush)\n\u001b[1;32m--> 545\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpub_thread\u001b[39m.\u001b[39;49mschedule(_schedule_in_thread)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\ipykernel\\iostream.py:251\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_events\u001b[39m.\u001b[39mappend(f)\n\u001b[0;32m    250\u001b[0m     \u001b[39m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event_pipe\u001b[39m.\u001b[39;49msend(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     f()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[39m=\u001b[39m zmq\u001b[39m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[39m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[39m=\u001b[39mcopy \u001b[39mor\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[39m.\u001b[39mgroup \u001b[39m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msend(data, flags\u001b[39m=\u001b[39;49mflags, copy\u001b[39m=\u001b[39;49mcopy, track\u001b[39m=\u001b[39;49mtrack)\n",
      "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", \n",
    "    factor=0.2, # new_lr = lr * factor.\n",
    "    patience=2,\n",
    "    cooldown=2, # number of epochs to wait before resuming normal operation after lr has been reduced.  \n",
    "    min_lr=0\n",
    ")\n",
    "model.fit(X_train, y_train, epochs= 100, batch_size = 100, validation_split=0.2, callbacks=[early, reduce_lr])\n",
    "\n",
    "model.save('conv_red8.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  339/13806 [..............................] - ETA: 7:51"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\code\\skkukdt_minzy\\DeepLearning\\project.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pred_y_train \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39mevaluate(X_train, y_train))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X44sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m pred_y_test \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\keras\\engine\\training.py:2253\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   2252\u001b[0m     callbacks\u001b[39m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 2253\u001b[0m     tmp_batch_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_function(iterator)\n\u001b[0;32m   2254\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2255\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred_y_train = model.predict(X_train)\n",
    "print(model.evaluate(X_train, y_train))\n",
    "\n",
    "pred_y_test = model.predict(X_test)\n",
    "print(model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_org = pd.read_csv(r'data/train_aug.csv')\n",
    "train_org = train_org.dropna()\n",
    "test_org = pd.read_csv(r'data/test_aug.csv')\n",
    "train_org['pred'] = np.where(pred_y_train > 0.5, 1, 0)\n",
    "test_org['pred'] = np.where(pred_y_test > 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\code\\skkukdt_minzy\\DeepLearning\\project.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_test \u001b[39m=\u001b[39m pad_sequences(text_sequences_test, maxlen\u001b[39m=\u001b[39mMAX_SEQUENCE_LENGTH, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpre\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m# 문장의 길이가 100 글자가 넘어가면 자르고, 모자르면 0으로 채워 넣는다.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X46sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m y_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(test_label) \u001b[39m# 각 리뷰의 감정을 넘파이 배열로 만든다.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m pred_y_test \u001b[39m=\u001b[39m model2\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m test_org[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(pred_y_test \u001b[39m>\u001b[39m \u001b[39m0.5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/code/skkukdt_minzy/DeepLearning/project.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(classification_report(test_org[\u001b[39m'\u001b[39m\u001b[39mimmoral\u001b[39m\u001b[39m'\u001b[39m], test_org[\u001b[39m'\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m'\u001b[39m]))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "test = pd.read_csv(r'data/champions.csv')\n",
    "test_org = pd.read_csv(r'data/champions.csv')\n",
    "test = test.fillna(0)\n",
    "test_org = test_org.fillna(0)\n",
    "test['text'] = test['text'].apply(lambda x : j2hcj(h2j(x)))\n",
    "test_list = textToList(test['text'])\n",
    "test_label = test['immoral']\n",
    "text_sequences_test = tokenizer.texts_to_sequences(test_list)\n",
    "X_test = pad_sequences(text_sequences_test, maxlen=MAX_SEQUENCE_LENGTH, padding='pre') # 문장의 길이가 100 글자가 넘어가면 자르고, 모자르면 0으로 채워 넣는다.\n",
    "y_test = np.array(test_label) # 각 리뷰의 감정을 넘파이 배열로 만든다.\n",
    "\n",
    "# pred_y_test = model2.predict(X_test)\n",
    "# test_org['pred'] = np.where(pred_y_test > 0.5, 1, 0)\n",
    "# print(classification_report(test_org['immoral'], test_org['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 875us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       269\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.91       269\n",
      "   macro avg       0.50      0.46      0.48       269\n",
      "weighted avg       1.00      0.91      0.95       269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\llljw\\AppData\\Local\\Temp\\ipykernel_17788\\2565546387.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test = pd.read_csv(r\"C:\\Users\\llljw\\Downloads\\clean.txt\", sep = 'aaaaaaaaaaaaaaaaaaaaaaaa')\n",
      "c:\\Users\\llljw\\anaconda3\\envs\\mzpark\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llljw\\anaconda3\\envs\\mzpark\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\llljw\\anaconda3\\envs\\mzpark\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = pd.read_csv(r\"C:\\Users\\llljw\\Downloads\\clean.txt\", sep = 'aaaaaaaaaaaaaaaaaaaaaaaa')\n",
    "test.columns = ['text']\n",
    "test['immoral'] = 0\n",
    "test_org = test.copy()\n",
    "test = test.fillna(0)\n",
    "test_org = test_org.fillna(0)\n",
    "test['text'] = test['text'].apply(lambda x : j2hcj(h2j(x)))\n",
    "test_list = textToList(test['text'])\n",
    "test_label = test['immoral']\n",
    "text_sequences_test = tokenizer.texts_to_sequences(test_list)\n",
    "X_test = pad_sequences(text_sequences_test, maxlen=MAX_SEQUENCE_LENGTH, padding='pre') # 문장의 길이가 100 글자가 넘어가면 자르고, 모자르면 0으로 채워 넣는다.\n",
    "y_test = np.array(test_label) # 각 리뷰의 감정을 넘파이 배열로 만든다.\n",
    "\n",
    "pred_y_test = model2.predict(X_test)\n",
    "test_org['pred'] = np.where(pred_y_test > 0.5, 1, 0)\n",
    "print(classification_report(test_org['immoral'], test_org['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77    333523\n",
      "           1       0.24      0.21      0.23    108258\n",
      "\n",
      "    accuracy                           0.65    441781\n",
      "   macro avg       0.50      0.50      0.50    441781\n",
      "weighted avg       0.63      0.65      0.64    441781\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91     41924\n",
      "           1       0.81      0.65      0.72     14718\n",
      "\n",
      "    accuracy                           0.87     56642\n",
      "   macro avg       0.84      0.80      0.82     56642\n",
      "weighted avg       0.86      0.87      0.86     56642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_org['immoral'], train_org['pred']))\n",
    "print(classification_report(test_org['immoral'], test_org['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 8s 32ms/step\n",
      "version1.h5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.09      0.17      4859\n",
      "         1.0       0.25      0.89      0.39      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.29      6463\n",
      "   macro avg       0.24      0.25      0.14      6463\n",
      "weighted avg       0.61      0.29      0.22      6463\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 14s 61ms/step\n",
      "version2.h5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.38      0.50      4859\n",
      "         1.0       0.24      0.61      0.35      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43      6463\n",
      "   macro avg       0.25      0.25      0.21      6463\n",
      "weighted avg       0.62      0.43      0.46      6463\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202/202 [==============================] - 8s 33ms/step\n",
      "version3.h5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.45      0.57      4859\n",
      "         1.0       0.26      0.58      0.36      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.48      6463\n",
      "   macro avg       0.26      0.26      0.23      6463\n",
      "weighted avg       0.64      0.48      0.52      6463\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "modelName = []\n",
    "# models.append(tf.keras.models.load_model('conv3.h5'))\n",
    "# modelName.append('conv3.h5')\n",
    "# models.append(tf.keras.models.load_model('conv_red0.h5'))\n",
    "# modelName.append('conv_red0.h5')\n",
    "# models.append(tf.keras.models.load_model('conv_red6.h5'))\n",
    "# modelName.append('conv_red6.h5')\n",
    "# models.append(tf.keras.models.load_model('conv_red5.h5'))\n",
    "# modelName.append('conv_red5.h5')\n",
    "models.append(tf.keras.models.load_model('version1.h5'))\n",
    "modelName.append('version1.h5')\n",
    "models.append(tf.keras.models.load_model('version2.h5'))\n",
    "modelName.append('version2.h5')\n",
    "models.append(tf.keras.models.load_model('version3.h5'))\n",
    "modelName.append('version3.h5')\n",
    "pred = []\n",
    "for m, name in zip(models, modelName):\n",
    "    pred_y_test = m.predict(X_test)\n",
    "    pred.append(pred_y_test.reshape(-1,))\n",
    "    pred_y_test = np.where(pred_y_test > 1, 1, 0)\n",
    "    print(name)\n",
    "    print(classification_report(y_test, pred_y_test.reshape(-1,)))\n",
    "    print('*' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_b = []\n",
    "for p in pred:\n",
    "    pred_b.append(np.where(p > 0.5, 1, 0))\n",
    "pred_sum = np.sum(pred_b, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.04      0.07      4859\n",
      "         1.0       0.25      0.97      0.40      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.27      6463\n",
      "   macro avg       0.25      0.25      0.12      6463\n",
      "weighted avg       0.64      0.27      0.15      6463\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.26      0.39      4859\n",
      "         1.0       0.24      0.71      0.36      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.37      6463\n",
      "   macro avg       0.24      0.24      0.19      6463\n",
      "weighted avg       0.61      0.37      0.38      6463\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.29      0.42      4859\n",
      "         1.0       0.25      0.73      0.38      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.40      6463\n",
      "   macro avg       0.25      0.26      0.20      6463\n",
      "weighted avg       0.64      0.40      0.41      6463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_b = []\n",
    "for p in pred:\n",
    "    mn = np.where(p > 0.5, 1, 0)\n",
    "    print(classification_report(y_test, mn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['immoral'] > 1, 'immoral'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.09      0.16      4859\n",
      "         1.0       0.25      0.90      0.39      1602\n",
      "         2.0       0.00      0.00      0.00         1\n",
      "         4.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.29      6463\n",
      "   macro avg       0.25      0.25      0.14      6463\n",
      "weighted avg       0.62      0.29      0.22      6463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\user\\anaconda3\\envs\\mzp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(pred)\n",
    "pred_f = df.mean(axis = 0).values\n",
    "mn = np.where(pred_f > 0.5, 1, 0)\n",
    "print(classification_report(y_test, mn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_org = pd.read_csv(r'data/champions.csv')\n",
    "test_org['pred_sum'] = pred_sum\n",
    "test_org['pred_f'] = pred_f\n",
    "test_org\n",
    "test_org[['pred_f', 'pred_sum', 'immoral', 'text']].to_csv('cmp_check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6463"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_org[test_org['pred_f'] > 0.8][['pred_f', 'pred_sum', 'immoral', 'text']].to_csv('over8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mzp",
   "language": "python",
   "name": "mzp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
