{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\dataset\\healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17492\\1120506178.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  sns.heatmap(df.corr(), annot=True, cmap='coolwarm').set(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Correlation between the data')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm').set(\n",
    "    title = \"Correlation between the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['gender'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ever_married.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['ever_married'] == 'Yes', 'married'] = 1\n",
    "df.loc[df['ever_married'] == 'No', 'married'] = 0\n",
    "df.ever_married.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "      <th>married</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>Female</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>children</td>\n",
       "      <td>Rural</td>\n",
       "      <td>103.08</td>\n",
       "      <td>18.6</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>Female</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>Male</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>Female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Govt_job</td>\n",
       "      <td>Urban</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4908 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender   age  hypertension  heart_disease      work_type Residence_type  \\\n",
       "0       Male  67.0             0              1        Private          Urban   \n",
       "2       Male  80.0             0              1        Private          Rural   \n",
       "3     Female  49.0             0              0        Private          Urban   \n",
       "4     Female  79.0             1              0  Self-employed          Rural   \n",
       "5       Male  81.0             0              0        Private          Urban   \n",
       "...      ...   ...           ...            ...            ...            ...   \n",
       "5104  Female  13.0             0              0       children          Rural   \n",
       "5106  Female  81.0             0              0  Self-employed          Urban   \n",
       "5107  Female  35.0             0              0  Self-employed          Rural   \n",
       "5108    Male  51.0             0              0        Private          Rural   \n",
       "5109  Female  44.0             0              0       Govt_job          Urban   \n",
       "\n",
       "      avg_glucose_level   bmi   smoking_status  stroke  married  \n",
       "0                228.69  36.6  formerly smoked       1      1.0  \n",
       "2                105.92  32.5     never smoked       1      1.0  \n",
       "3                171.23  34.4           smokes       1      1.0  \n",
       "4                174.12  24.0     never smoked       1      1.0  \n",
       "5                186.21  29.0  formerly smoked       1      1.0  \n",
       "...                 ...   ...              ...     ...      ...  \n",
       "5104             103.08  18.6          Unknown       0      0.0  \n",
       "5106             125.20  40.0     never smoked       0      1.0  \n",
       "5107              82.99  30.6     never smoked       0      1.0  \n",
       "5108             166.29  25.6  formerly smoked       0      1.0  \n",
       "5109              85.28  26.2          Unknown       0      1.0  \n",
       "\n",
       "[4908 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['id', 'ever_married'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4908 entries, 0 to 5109\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             4908 non-null   object \n",
      " 1   age                4908 non-null   float64\n",
      " 2   hypertension       4908 non-null   int64  \n",
      " 3   heart_disease      4908 non-null   int64  \n",
      " 4   work_type          4908 non-null   object \n",
      " 5   Residence_type     4908 non-null   object \n",
      " 6   avg_glucose_level  4908 non-null   float64\n",
      " 7   bmi                4908 non-null   float64\n",
      " 8   smoking_status     4908 non-null   object \n",
      " 9   stroke             4908 non-null   int64  \n",
      " 10  married            4908 non-null   float64\n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 460.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>married</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Rural</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5104</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>103.08</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.20</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.99</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.29</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5109</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.28</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4908 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  hypertension  heart_disease  avg_glucose_level   bmi  stroke  \\\n",
       "0     67.0             0              1             228.69  36.6       1   \n",
       "2     80.0             0              1             105.92  32.5       1   \n",
       "3     49.0             0              0             171.23  34.4       1   \n",
       "4     79.0             1              0             174.12  24.0       1   \n",
       "5     81.0             0              0             186.21  29.0       1   \n",
       "...    ...           ...            ...                ...   ...     ...   \n",
       "5104  13.0             0              0             103.08  18.6       0   \n",
       "5106  81.0             0              0             125.20  40.0       0   \n",
       "5107  35.0             0              0              82.99  30.6       0   \n",
       "5108  51.0             0              0             166.29  25.6       0   \n",
       "5109  44.0             0              0              85.28  26.2       0   \n",
       "\n",
       "      married  gender_Female  gender_Male  work_type_Govt_job  \\\n",
       "0         1.0              0            1                   0   \n",
       "2         1.0              0            1                   0   \n",
       "3         1.0              1            0                   0   \n",
       "4         1.0              1            0                   0   \n",
       "5         1.0              0            1                   0   \n",
       "...       ...            ...          ...                 ...   \n",
       "5104      0.0              1            0                   0   \n",
       "5106      1.0              1            0                   0   \n",
       "5107      1.0              1            0                   0   \n",
       "5108      1.0              0            1                   0   \n",
       "5109      1.0              1            0                   1   \n",
       "\n",
       "      work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
       "0                          0                  1                        0   \n",
       "2                          0                  1                        0   \n",
       "3                          0                  1                        0   \n",
       "4                          0                  0                        1   \n",
       "5                          0                  1                        0   \n",
       "...                      ...                ...                      ...   \n",
       "5104                       0                  0                        0   \n",
       "5106                       0                  0                        1   \n",
       "5107                       0                  0                        1   \n",
       "5108                       0                  1                        0   \n",
       "5109                       0                  0                        0   \n",
       "\n",
       "      work_type_children  Residence_type_Rural  Residence_type_Urban  \\\n",
       "0                      0                     0                     1   \n",
       "2                      0                     1                     0   \n",
       "3                      0                     0                     1   \n",
       "4                      0                     1                     0   \n",
       "5                      0                     0                     1   \n",
       "...                  ...                   ...                   ...   \n",
       "5104                   1                     1                     0   \n",
       "5106                   0                     0                     1   \n",
       "5107                   0                     1                     0   \n",
       "5108                   0                     1                     0   \n",
       "5109                   0                     0                     1   \n",
       "\n",
       "      smoking_status_Unknown  smoking_status_formerly smoked  \\\n",
       "0                          0                               1   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "5                          0                               1   \n",
       "...                      ...                             ...   \n",
       "5104                       1                               0   \n",
       "5106                       0                               0   \n",
       "5107                       0                               0   \n",
       "5108                       0                               1   \n",
       "5109                       1                               0   \n",
       "\n",
       "      smoking_status_never smoked  smoking_status_smokes  \n",
       "0                               0                      0  \n",
       "2                               1                      0  \n",
       "3                               0                      1  \n",
       "4                               1                      0  \n",
       "5                               0                      0  \n",
       "...                           ...                    ...  \n",
       "5104                            0                      0  \n",
       "5106                            1                      0  \n",
       "5107                            1                      0  \n",
       "5108                            0                      0  \n",
       "5109                            0                      0  \n",
       "\n",
       "[4908 rows x 20 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummy = pd.get_dummies(df)\n",
    "df_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_dummy.drop('stroke', axis = 1)\n",
    "y_data = df_dummy.stroke\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# \n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, random_state = 333, test_size = 0.3, stratify = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000080 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000094 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 98, number of negative: 2192\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 636\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 97, number of negative: 2193\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 2290, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 146, number of negative: 3289\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 639\n",
      "[LightGBM] [Info] Number of data points in the train set: 3435, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.658022</td>\n",
       "      <td>16</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>11</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.630527</td>\n",
       "      <td>21</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.610119</td>\n",
       "      <td>26</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.658022</td>\n",
       "      <td>16</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>11</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.630527</td>\n",
       "      <td>21</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.610119</td>\n",
       "      <td>26</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.658022</td>\n",
       "      <td>16</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>11</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.630527</td>\n",
       "      <td>21</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.610119</td>\n",
       "      <td>26</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.658022</td>\n",
       "      <td>16</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>11</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.630527</td>\n",
       "      <td>21</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.610119</td>\n",
       "      <td>26</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.712727</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.551020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.658022</td>\n",
       "      <td>16</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.664683</td>\n",
       "      <td>11</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.530612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.630527</td>\n",
       "      <td>21</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.489796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'boosting_type': 'dart', 'class_weight': 'bal...</td>\n",
       "      <td>0.610119</td>\n",
       "      <td>26</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "0   {'boosting_type': 'dart', 'class_weight': 'bal...         0.712727   \n",
       "1   {'boosting_type': 'dart', 'class_weight': 'bal...         0.678571   \n",
       "2   {'boosting_type': 'dart', 'class_weight': 'bal...         0.658022   \n",
       "3   {'boosting_type': 'dart', 'class_weight': 'bal...         0.664683   \n",
       "4   {'boosting_type': 'dart', 'class_weight': 'bal...         0.630527   \n",
       "5   {'boosting_type': 'dart', 'class_weight': 'bal...         0.610119   \n",
       "6   {'boosting_type': 'dart', 'class_weight': 'bal...         0.712727   \n",
       "7   {'boosting_type': 'dart', 'class_weight': 'bal...         0.678571   \n",
       "8   {'boosting_type': 'dart', 'class_weight': 'bal...         0.658022   \n",
       "9   {'boosting_type': 'dart', 'class_weight': 'bal...         0.664683   \n",
       "10  {'boosting_type': 'dart', 'class_weight': 'bal...         0.630527   \n",
       "11  {'boosting_type': 'dart', 'class_weight': 'bal...         0.610119   \n",
       "12  {'boosting_type': 'dart', 'class_weight': 'bal...         0.712727   \n",
       "13  {'boosting_type': 'dart', 'class_weight': 'bal...         0.678571   \n",
       "14  {'boosting_type': 'dart', 'class_weight': 'bal...         0.658022   \n",
       "15  {'boosting_type': 'dart', 'class_weight': 'bal...         0.664683   \n",
       "16  {'boosting_type': 'dart', 'class_weight': 'bal...         0.630527   \n",
       "17  {'boosting_type': 'dart', 'class_weight': 'bal...         0.610119   \n",
       "18  {'boosting_type': 'dart', 'class_weight': 'bal...         0.712727   \n",
       "19  {'boosting_type': 'dart', 'class_weight': 'bal...         0.678571   \n",
       "20  {'boosting_type': 'dart', 'class_weight': 'bal...         0.658022   \n",
       "21  {'boosting_type': 'dart', 'class_weight': 'bal...         0.664683   \n",
       "22  {'boosting_type': 'dart', 'class_weight': 'bal...         0.630527   \n",
       "23  {'boosting_type': 'dart', 'class_weight': 'bal...         0.610119   \n",
       "24  {'boosting_type': 'dart', 'class_weight': 'bal...         0.712727   \n",
       "25  {'boosting_type': 'dart', 'class_weight': 'bal...         0.678571   \n",
       "26  {'boosting_type': 'dart', 'class_weight': 'bal...         0.658022   \n",
       "27  {'boosting_type': 'dart', 'class_weight': 'bal...         0.664683   \n",
       "28  {'boosting_type': 'dart', 'class_weight': 'bal...         0.630527   \n",
       "29  {'boosting_type': 'dart', 'class_weight': 'bal...         0.610119   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0                 1           0.770833           0.795918           0.571429  \n",
       "1                 6           0.750000           0.734694           0.551020  \n",
       "2                16           0.729167           0.714286           0.530612  \n",
       "3                11           0.708333           0.755102           0.530612  \n",
       "4                21           0.687500           0.714286           0.489796  \n",
       "5                26           0.687500           0.673469           0.469388  \n",
       "6                 1           0.770833           0.795918           0.571429  \n",
       "7                 6           0.750000           0.734694           0.551020  \n",
       "8                16           0.729167           0.714286           0.530612  \n",
       "9                11           0.708333           0.755102           0.530612  \n",
       "10               21           0.687500           0.714286           0.489796  \n",
       "11               26           0.687500           0.673469           0.469388  \n",
       "12                1           0.770833           0.795918           0.571429  \n",
       "13                6           0.750000           0.734694           0.551020  \n",
       "14               16           0.729167           0.714286           0.530612  \n",
       "15               11           0.708333           0.755102           0.530612  \n",
       "16               21           0.687500           0.714286           0.489796  \n",
       "17               26           0.687500           0.673469           0.469388  \n",
       "18                1           0.770833           0.795918           0.571429  \n",
       "19                6           0.750000           0.734694           0.551020  \n",
       "20               16           0.729167           0.714286           0.530612  \n",
       "21               11           0.708333           0.755102           0.530612  \n",
       "22               21           0.687500           0.714286           0.489796  \n",
       "23               26           0.687500           0.673469           0.469388  \n",
       "24                1           0.770833           0.795918           0.571429  \n",
       "25                6           0.750000           0.734694           0.551020  \n",
       "26               16           0.729167           0.714286           0.530612  \n",
       "27               11           0.708333           0.755102           0.530612  \n",
       "28               21           0.687500           0.714286           0.489796  \n",
       "29               26           0.687500           0.673469           0.469388  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "param = {'boosting_type' : ['dart'],\n",
    "         'max_depth' : [10, 20, 30, 40, 50],\n",
    "    'num_leaves':[5, 6, 7, 8, 9, 10],\n",
    "         \"objective\" : ['binary'], \n",
    "         'class_weight' : ['balanced']}\n",
    "grid = GridSearchCV(model, param_grid = param, cv=3, refit = True ,  scoring='recall')\n",
    "grid.fit(x_train, y_train)\n",
    "pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, class_weight=&#x27;balanced&#x27;, max_depth=10,\n",
       "               num_leaves=5, objective=&#x27;binary&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, class_weight=&#x27;balanced&#x27;, max_depth=10,\n",
       "               num_leaves=5, objective=&#x27;binary&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight='balanced', max_depth=10,\n",
       "               num_leaves=5, objective='binary')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 146, number of negative: 3289\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 639\n",
      "[LightGBM] [Info] Number of data points in the train set: 3435, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86      3289\n",
      "           1       0.14      0.88      0.24       146\n",
      "\n",
      "    accuracy                           0.76      3435\n",
      "   macro avg       0.57      0.82      0.55      3435\n",
      "weighted avg       0.96      0.76      0.83      3435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84      1410\n",
      "           1       0.11      0.78      0.20        63\n",
      "\n",
      "    accuracy                           0.73      1473\n",
      "   macro avg       0.55      0.75      0.52      1473\n",
      "weighted avg       0.95      0.73      0.81      1473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "m_lgb = lgb.LGBMClassifier(boosting_type='dart', class_weight='balanced', max_depth=10, num_leaves=5, objective='binary')\n",
    "m_lgb.fit(x_train, y_train)\n",
    "print(classification_report(y_train, m_lgb.predict(x_train)))\n",
    "print(classification_report(y_test, m_lgb.predict(x_test)))\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.75      0.86      3289\n",
    "#            1       0.14      0.88      0.24       146\n",
    "\n",
    "#     accuracy                           0.76      3435\n",
    "#    macro avg       0.57      0.82      0.55      3435\n",
    "# weighted avg       0.96      0.76      0.83      3435\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.73      0.84      1410\n",
    "#            1       0.11      0.78      0.20        63\n",
    "\n",
    "#     accuracy                           0.73      1473\n",
    "#    macro avg       0.55      0.75      0.52      1473\n",
    "# weighted avg       0.95      0.73      0.81      1473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 10, 'num_leaves': 5, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 10, 'num_leaves': 6, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 10, 'num_leaves': 7, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 10, 'num_leaves': 8, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 10, 'num_leaves': 9, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 10, 'num_leaves': 10, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 20, 'num_leaves': 5, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 20, 'num_leaves': 6, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 20, 'num_leaves': 7, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 20, 'num_leaves': 8, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 20, 'num_leaves': 9, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 20, 'num_leaves': 10, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 30, 'num_leaves': 5, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 30, 'num_leaves': 6, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 30, 'num_leaves': 7, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 30, 'num_leaves': 8, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 30, 'num_leaves': 9, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 30, 'num_leaves': 10, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 40, 'num_leaves': 5, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 40, 'num_leaves': 6, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 40, 'num_leaves': 7, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 40, 'num_leaves': 8, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 40, 'num_leaves': 9, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 40, 'num_leaves': 10, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 50, 'num_leaves': 5, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 50, 'num_leaves': 6, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 50, 'num_leaves': 7, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 50, 'num_leaves': 8, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 50, 'num_leaves': 9, 'objective': 'binary'}\n",
      "{'boosting_type': 'dart', 'class_weight': 'balanced', 'max_depth': 50, 'num_leaves': 10, 'objective': 'binary'}\n"
     ]
    }
   ],
   "source": [
    "for p in (pd.DataFrame(grid.cv_results_)['params']):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\my_python_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "18 fits failed out of a total of 72.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\my_python_env2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\my_python_env2\\lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\my_python_env2\\lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\anaconda3\\envs\\my_python_env2\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'kernel' parameter of SVC must be a str among {'linear', 'poly', 'rbf', 'precomputed', 'sigmoid'} or a callable. Got 'ploy' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\anaconda3\\envs\\my_python_env2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.80201247        nan 0.66666667 0.66666667 0.80881519        nan\n",
      " 0.62485828 0.40972222 0.80187075        nan 0.82242063 0.38265306\n",
      " 0.80187075        nan 0.78132086 0.67913832 0.81575964        nan\n",
      " 0.80881519 0.65873016 0.81547619        nan 0.80187075 0.65192744]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'kern...</td>\n",
       "      <td>0.802012</td>\n",
       "      <td>6</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'kern...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'kern...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.001, 'class_weight': 'balanced', 'kern...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'kerne...</td>\n",
       "      <td>0.808815</td>\n",
       "      <td>4</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'kerne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'kerne...</td>\n",
       "      <td>0.624858</td>\n",
       "      <td>16</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.653061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'kerne...</td>\n",
       "      <td>0.409722</td>\n",
       "      <td>17</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>0.801871</td>\n",
       "      <td>7</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>0.822421</td>\n",
       "      <td>1</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>0.382653</td>\n",
       "      <td>18</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'kernel':...</td>\n",
       "      <td>0.801871</td>\n",
       "      <td>7</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'kernel':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'kernel':...</td>\n",
       "      <td>0.781321</td>\n",
       "      <td>10</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'kernel':...</td>\n",
       "      <td>0.679138</td>\n",
       "      <td>11</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'kernel'...</td>\n",
       "      <td>0.815760</td>\n",
       "      <td>2</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'kernel'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'kernel'...</td>\n",
       "      <td>0.808815</td>\n",
       "      <td>4</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'kernel'...</td>\n",
       "      <td>0.658730</td>\n",
       "      <td>14</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.734694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>0.801871</td>\n",
       "      <td>7</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.693878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'C': 100, 'class_weight': 'balanced', 'kernel...</td>\n",
       "      <td>0.651927</td>\n",
       "      <td>15</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score  \\\n",
       "0   {'C': 0.001, 'class_weight': 'balanced', 'kern...         0.802012   \n",
       "1   {'C': 0.001, 'class_weight': 'balanced', 'kern...              NaN   \n",
       "2   {'C': 0.001, 'class_weight': 'balanced', 'kern...         0.666667   \n",
       "3   {'C': 0.001, 'class_weight': 'balanced', 'kern...         0.666667   \n",
       "4   {'C': 0.01, 'class_weight': 'balanced', 'kerne...         0.808815   \n",
       "5   {'C': 0.01, 'class_weight': 'balanced', 'kerne...              NaN   \n",
       "6   {'C': 0.01, 'class_weight': 'balanced', 'kerne...         0.624858   \n",
       "7   {'C': 0.01, 'class_weight': 'balanced', 'kerne...         0.409722   \n",
       "8   {'C': 0.1, 'class_weight': 'balanced', 'kernel...         0.801871   \n",
       "9   {'C': 0.1, 'class_weight': 'balanced', 'kernel...              NaN   \n",
       "10  {'C': 0.1, 'class_weight': 'balanced', 'kernel...         0.822421   \n",
       "11  {'C': 0.1, 'class_weight': 'balanced', 'kernel...         0.382653   \n",
       "12  {'C': 1, 'class_weight': 'balanced', 'kernel':...         0.801871   \n",
       "13  {'C': 1, 'class_weight': 'balanced', 'kernel':...              NaN   \n",
       "14  {'C': 1, 'class_weight': 'balanced', 'kernel':...         0.781321   \n",
       "15  {'C': 1, 'class_weight': 'balanced', 'kernel':...         0.679138   \n",
       "16  {'C': 10, 'class_weight': 'balanced', 'kernel'...         0.815760   \n",
       "17  {'C': 10, 'class_weight': 'balanced', 'kernel'...              NaN   \n",
       "18  {'C': 10, 'class_weight': 'balanced', 'kernel'...         0.808815   \n",
       "19  {'C': 10, 'class_weight': 'balanced', 'kernel'...         0.658730   \n",
       "20  {'C': 100, 'class_weight': 'balanced', 'kernel...         0.815476   \n",
       "21  {'C': 100, 'class_weight': 'balanced', 'kernel...              NaN   \n",
       "22  {'C': 100, 'class_weight': 'balanced', 'kernel...         0.801871   \n",
       "23  {'C': 100, 'class_weight': 'balanced', 'kernel...         0.651927   \n",
       "\n",
       "    rank_test_score  split0_test_score  split1_test_score  split2_test_score  \n",
       "0                 6           0.895833           0.836735           0.673469  \n",
       "1                19                NaN                NaN                NaN  \n",
       "2                12           0.000000           1.000000           1.000000  \n",
       "3                12           0.000000           1.000000           1.000000  \n",
       "4                 4           0.895833           0.836735           0.693878  \n",
       "5                19                NaN                NaN                NaN  \n",
       "6                16           0.854167           0.367347           0.653061  \n",
       "7                17           0.229167           0.530612           0.469388  \n",
       "8                 7           0.875000           0.836735           0.693878  \n",
       "9                19                NaN                NaN                NaN  \n",
       "10                1           0.895833           0.857143           0.714286  \n",
       "11               18           0.250000           0.489796           0.408163  \n",
       "12                7           0.875000           0.836735           0.693878  \n",
       "13               19                NaN                NaN                NaN  \n",
       "14               10           0.854167           0.816327           0.673469  \n",
       "15               11           0.833333           0.795918           0.408163  \n",
       "16                2           0.916667           0.836735           0.693878  \n",
       "17               19                NaN                NaN                NaN  \n",
       "18                4           0.895833           0.836735           0.693878  \n",
       "19               14           0.833333           0.734694           0.408163  \n",
       "20                3           0.875000           0.836735           0.734694  \n",
       "21               19                NaN                NaN                NaN  \n",
       "22                7           0.875000           0.836735           0.693878  \n",
       "23               15           0.833333           0.714286           0.408163  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model = SVC()\n",
    "\n",
    "param = {'C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "         'kernel' : ['linear', 'ploy', 'rbf', 'sigmoid'], \n",
    "         'class_weight' : ['balanced']}\n",
    "grid = GridSearchCV(model, param_grid = param, cv=3, refit = True ,  scoring='recall')\n",
    "grid.fit(x_train, y_train)\n",
    "pd.DataFrame(grid.cv_results_)[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.001, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "{'C': 0.001, 'class_weight': 'balanced', 'kernel': 'ploy'}\n",
      "{'C': 0.001, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "{'C': 0.001, 'class_weight': 'balanced', 'kernel': 'sigmoid'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'kernel': 'ploy'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'kernel': 'sigmoid'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'kernel': 'ploy'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "{'C': 0.1, 'class_weight': 'balanced', 'kernel': 'sigmoid'}\n",
      "{'C': 1, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "{'C': 1, 'class_weight': 'balanced', 'kernel': 'ploy'}\n",
      "{'C': 1, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "{'C': 1, 'class_weight': 'balanced', 'kernel': 'sigmoid'}\n",
      "{'C': 10, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "{'C': 10, 'class_weight': 'balanced', 'kernel': 'ploy'}\n",
      "{'C': 10, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "{'C': 10, 'class_weight': 'balanced', 'kernel': 'sigmoid'}\n",
      "{'C': 100, 'class_weight': 'balanced', 'kernel': 'linear'}\n",
      "{'C': 100, 'class_weight': 'balanced', 'kernel': 'ploy'}\n",
      "{'C': 100, 'class_weight': 'balanced', 'kernel': 'rbf'}\n",
      "{'C': 100, 'class_weight': 'balanced', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "for p in (pd.DataFrame(grid.cv_results_)['params']):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.71      0.83      3289\n",
      "           1       0.11      0.81      0.20       146\n",
      "\n",
      "    accuracy                           0.72      3435\n",
      "   macro avg       0.55      0.76      0.51      3435\n",
      "weighted avg       0.95      0.72      0.80      3435\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81      1410\n",
      "           1       0.10      0.81      0.19        63\n",
      "\n",
      "    accuracy                           0.70      1473\n",
      "   macro avg       0.55      0.75      0.50      1473\n",
      "weighted avg       0.95      0.70      0.79      1473\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6900709219858157"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.svm import SVC\n",
    "m_svc = SVC(C= 0.1, class_weight= 'balanced', kernel= 'rbf')\n",
    "m_svc.fit(x_train, y_train)\n",
    "y_pred = m_svc.predict(x_test)\n",
    "print(classification_report(y_train, m_svc.predict(x_train)))\n",
    "print(classification_report(y_test, m_svc.predict(x_test)))\n",
    "train_rcl = recall_score(y_test, y_pred, pos_label = 0)\n",
    "train_rcl\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.71      0.83      3289\n",
    "#            1       0.11      0.81      0.20       146\n",
    "\n",
    "#     accuracy                           0.72      3435\n",
    "#    macro avg       0.55      0.76      0.51      3435\n",
    "# weighted avg       0.95      0.72      0.80      3435\n",
    "\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#            0       0.99      0.69      0.81      1410\n",
    "#            1       0.10      0.81      0.19        63\n",
    "\n",
    "#     accuracy                           0.70      1473\n",
    "#    macro avg       0.55      0.75      0.50      1473\n",
    "# weighted avg       0.95      0.70      0.79      1473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selenium",
   "language": "python",
   "name": "my_python_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
